{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 18 17:07:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   54C    P0    57W / 149W |   1745MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,\n",
    "          test_loader,\n",
    "          loss,\n",
    "          optimizer,\n",
    "          scheduler,\n",
    "          tb_path=\".\",\n",
    "          epochs = 1,\n",
    "          init_epoch=0):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device: {}\".format(device))\n",
    "    print('*****************')\n",
    "    \n",
    "    writer = SummaryWriter(tb_path)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "  \n",
    "    for epoch in range(init_epoch, init_epoch+epochs):\n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        \n",
    "        train_mean_loss = 0\n",
    "        \n",
    "        pbar = tqdm(total=len(train_loader))\n",
    "        \n",
    "        \n",
    "        model = model.train()\n",
    "        for i, (swn, s) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "\n",
    "            swn = swn.to(device)\n",
    "            s = s.to(device)\n",
    "            \n",
    "            cs = model.forward(swn)\n",
    "            loss_value = loss(cs, swn, s)\n",
    "            \n",
    "            \n",
    "            if torch.isnan(loss_value):\n",
    "                print(\"Error on {}\".format(i))\n",
    "                del cs\n",
    "                del swn\n",
    "                del s\n",
    "                del loss_value\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "                #return\n",
    "\n",
    "            loss_value.backward()\n",
    "            train_mean_loss += loss_value.data.cpu()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_description(\"Loss \\\"{}\\\"\".format(loss_value.data.cpu()))\n",
    "        \n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            del cs\n",
    "            del swn\n",
    "            del s\n",
    "            del loss_value\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        pbar.close()\n",
    "        train_mean_loss /= len(train_loader)\n",
    "        train_loss_history.append(train_mean_loss)\n",
    "        print(f\"Mean train loss: {train_mean_loss}:\")\n",
    "\n",
    "        example_audio = True\n",
    "        \n",
    "        test_mean_loss = 0\n",
    "        count = 0\n",
    "        model = model.eval()\n",
    "        for (swn, s) in train_loader:\n",
    "            \n",
    "\n",
    "            swn = swn.to(device)\n",
    "            s = s.to(device)\n",
    "\n",
    "            cs = model.forward(swn)\n",
    "            loss_value = loss(cs, swn, s)\n",
    "            count += 1\n",
    "            \n",
    "            if example_audio:\n",
    "                example_audio = False\n",
    "                writer.add_audio('Audio/clean', s[0,:].data.cpu(), sample_rate=16000)\n",
    "                writer.add_audio('Audio/with noise', swn[0,:].data.cpu(), sample_rate=16000)\n",
    "                writer.add_audio('Audio/predict', cs[0,:].data.cpu(), sample_rate=16000)\n",
    "            test_mean_loss += loss_value.data.cpu()\n",
    "            \n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            del cs\n",
    "            del swn\n",
    "            del s\n",
    "            del loss_value\n",
    "            \n",
    "\n",
    "        test_mean_loss /= count\n",
    "        test_loss_history.append(test_mean_loss)\n",
    "        print(f\"Mean test loss: {test_mean_loss}:\")\n",
    "\n",
    "\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_mean_loss, epoch)\n",
    "        writer.add_scalar('Loss/test', test_mean_loss, epoch)\n",
    "        print('---------------')\n",
    "    return train_loss_history, test_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speech_sources = list(Path('../data/cleaned/LIBRISPEECH/LibriSpeech/train-clean-100/').glob('*'))[:50]\n",
    "train_speech_files = np.concatenate([\n",
    "    list(path.glob('**/*.flac')) for path in train_speech_sources\n",
    "])\n",
    "\n",
    "test_speech_sources = list(Path('../data/cleaned/LIBRISPEECH/LibriSpeech/train-clean-100/').glob('*'))[50:55]\n",
    "test_speech_files = np.concatenate([\n",
    "    list(path.glob('**/*.flac')) for path in test_speech_sources\n",
    "])\n",
    "\n",
    "train_noise_sources = list(Path('../data/cleaned/DEMAND').glob('*'))[:8]\n",
    "train_noise_files = np.concatenate([\n",
    "    list(path.glob('**/*.wav')) for path in train_noise_sources\n",
    "])\n",
    "\n",
    "test_noise_sources = list(Path('../data/cleaned/DEMAND').glob('*'))[8:10]\n",
    "test_noise_files = np.concatenate([\n",
    "    list(path.glob('**/*.wav')) for path in test_noise_sources\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Experiment 1\"\n",
    "CONFIG = {\n",
    "    \"name\": NAME, \n",
    "    \"snr\": [15, 10, 5, 0],\n",
    "    \"results_path\": \"../results/{}\".format(NAME),\n",
    "    \"tensorboard_path\": \"../results/tb/{}\".format(NAME),\n",
    "    \"train_samples\": 20,\n",
    "    \"test_samples\": 10,\n",
    "    \"train_speech_batch_size\": 10,\n",
    "    \"test_speech_batch_size\": 1,\n",
    "    \"shuffle\": True,\n",
    "    \"train_speech\": train_speech_files,\n",
    "    \"test_speech\": test_speech_files,\n",
    "    \"train_noise\": train_noise_files,\n",
    "    \"test_noise\": test_noise_files,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = src.SpeechWithNoiseDataset(\n",
    "    CONFIG[\"train_speech\"],\n",
    "    CONFIG[\"train_noise\"],\n",
    "    speech_batch_size=CONFIG[\"train_speech_batch_size\"],\n",
    "    noise_by_speech=4,\n",
    "    max_len=None if CONFIG[\"shuffle\"] else CONFIG[\"train_samples\"],\n",
    "    snr=CONFIG[\"snr\"]\n",
    ")\n",
    "if CONFIG[\"shuffle\"]:\n",
    "    sampler = RandomSampler(\n",
    "        train_dataset,\n",
    "        replacement=True, \n",
    "        num_samples=CONFIG[\"train_samples\"]\n",
    "    )\n",
    "else:\n",
    "    sampler = None\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = None,\n",
    "    sampler = sampler,\n",
    "    num_workers = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = src.SpeechWithNoiseDataset(\n",
    "    CONFIG[\"test_speech\"],\n",
    "    CONFIG[\"test_noise\"],\n",
    "    speech_batch_size=CONFIG[\"test_speech_batch_size\"],\n",
    "    noise_by_speech=4,\n",
    "    max_len=None if CONFIG[\"shuffle\"] else CONFIG[\"test_samples\"],\n",
    "    snr=CONFIG[\"snr\"]\n",
    ")\n",
    "if CONFIG[\"shuffle\"]:\n",
    "    sampler = RandomSampler(\n",
    "        test_dataset,\n",
    "        replacement=True, \n",
    "        num_samples=CONFIG[\"test_samples\"]\n",
    "    )\n",
    "else:\n",
    "    sampler = None\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = None,\n",
    "    sampler = sampler,\n",
    "    num_workers = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = src.DCUnet10(iscomplex = True)\n",
    "model = src.EnhModel(conv, 64*16, 16*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "def loss(cs, swn, s, **kvargs):\n",
    "    return src.wsdr_loss(\n",
    "        cs,\n",
    "        swn[:, 0:cs.shape[1]],\n",
    "        s[:, 0:cs.shape[1]],\n",
    "        **kvargs\n",
    "    )\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    tb_path=CONFIG[\"tensorboard_path\"],\n",
    "    init_epoch=5,\n",
    "    epochs = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CONFIG[\"results_path\"], exist_ok = True) \n",
    "torch.save(model, os.path.join(CONFIG[\"results_path\"], \"mode.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CONFIG[\"results_path\"], exist_ok = True) \n",
    "torch.save(model.state_dict(), os.path.join(CONFIG[\"results_path\"], \"mode_state.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesq import pesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028099ca5ed94e10b60d292e69575190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "mean_pesq = 0\n",
    "model = model.cpu()\n",
    "for i in tqdm(range(N)):\n",
    "    swn, s = test_dataset[i]\n",
    "    cs = model(swn[[0], :])\n",
    "    mean_pesq += pesq(s[0,:cs.shape[1]].data.numpy(), cs[0,:].data.numpy(), fs=16000)\n",
    "mean_pesq /= N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.313958193063736"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pesq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
